---
layout: about
title: about
permalink: /
subtitle: PhD student at <a href="https://ie.kaist.ac.kr/">KAIST</a>. <a herf="https://mila.quebec/en/minsu-kim">Collaborating researcher</a> at Mila 

profile:
  align: right
  image:
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Starting in March 2025, I will be joining the [KAIST-Mila Prefrontal AI Research Center](https://mlml.kaist.ac.kr/pair) as a *postdoctoral researcher*, jointly hosted by:

- [Prof. Yoshua Bengio](https://yoshuabengio.org/)
- [Prof. Sungjin Ahn](https://mlml.kaist.ac.kr/sungjinahn)
- [Prof. Sungsoo Ahn](https://sites.google.com/view/sungsooahn0215/home)

This research center focuses on System 2 Deep Learning, a collaborative effort between KAIST and Mila. Our research topics include prefrontal AI, safety-guaranteed AGI, and AI for Science.

---

### Backgrounds

I'm a Ph.D. candidate at KAIST, advised by [Prof. Jinkyoo Park](http://silab.kaist.ac.kr/our-team/). During my Ph.D., I've had the pleasure of collaborating with two esteemed external professors:

- [Prof. Sungsoo Ahn](https://sites.google.com/view/sungsooahn0215/home) and his group members, such as [Hyosoon Jang](https://hsjang0.github.io/hsjang/).
- [Prof. Yoshua Bengio](https://yoshuabengio.org/) at Mila.

I have engaged in deep collaborations with researchers at Mila, physically visiting [Yoshua Bengio](https://yoshuabengio.org/)'s group from December 2023 to May 2024. Currently, I am continuing my work as a <a herf="https://mila.quebec/en/minsu-kim">Collaborating researcher</a> at Mila until February 2025. I have been fortunate to work with many researchers, including [Emmanuel Bengio](https://folinoid.com/), [Nikolay Malkin](https://malkin1729.github.io/), [Seanie Lee](https://seanie12.github.io/), [Moksh Jain](https://mj10.github.io/), [Siddarth Venkatraman](https://hyperpotatoneo.github.io/), and [Dinghuai Zhang](https://zdhnarsil.github.io/), among many others.

I received my master's degree from [Prof. Joungho Kim](https://tera.kaist.ac.kr/), an expert in designing 3D ICs (e.g., HBM) for SI/PI performance.

### Research

I'm currently focused on advancing reasoning in deep learning and its applications across various domains, including large language models and scientific discovery. My short-term research goals involve fine-tuning large models using Bayesian posterior inference, leveraging the off-policy amortized inference capabilities of GFlowNets. For my long-term research, I'm interested in System 2 deep learning, which entails developing world models that can measure uncertainty and represent causal relationships. I believe that such world models should also capture harmful risks and enable the creation of pessimistic agents to avoid misaligned actions, thereby guarantees safety.

Additionally, I have a keen interest in combinatorial optimization (CO) and NP-hard algorithmic problems. I often utilize deep learning methods to address these challenges or incorporate techniques from CO, such as local search and tree search, into deep learning. I believe that CO and NP-hard problems are closely related to reasoning in deep learning and System 2 deep learning, and I am eager to explore these connections further.

To sum up, my research methodology includes:
- GFlowNets (e.g., *better exploration and credit assignments for GFlowNets*)
- Diffusion Models (e.g., *discrete diffusion and Boltzmann generator*)
- Deep Reinforcement Learning (e.g., *replay training for sample efficient DRL*)

My research applications includes:
- Scientific discovery (*e.g., de novo discovery of small molecular graphs*)
- Hardware design optimization (*e.g., Placement of decoupling capacitance, and channel routing*)
- Combinatorial optimization (*e.g., Vehicle routing, scheduling, and graph covering*).
- Alignment of large multimodal model (*Finetuning text-to-image model with human feedback*)
- Alignment of large language model (*e.g., Red-Teaming with safety tuning, RLHF, amortizing chain-of-thought*)

#### My research at master prieods. 

One surprising fact about my background is that I worked in hardware system design and analysis from 2020 to 2022 during my master's degree. My focus was on signal integrity and power integrity in 2.5D/3D semiconductor architectures, including high-bandwidth memory (HBM) modules. I developed advanced deep learning algorithms to automate and optimize hardware layout design and device placement. These experiences provided me with a deep understanding of computing systems and HBM, which are crucial for AI computing, as well as practical knowledge in using deep learning methods for hardware optimization challenges.



### Education 

- Ph.D. Candidate at KAIST IE
  - Advisor: Jinkyoo Park
  - **2022.Mar ~ 2025.Feb (Expected)**
- M.S. at KAIST EE
  - Advisor: Joungho Kim
  - **2020.Mar ~ 2022.Feb**
- B.S. at KAIST, Math and CS (Dual Degree)
  - **2015.Mar ~ 2020.Feb**

### Awards
- **Google Conference Scholarship** for ICLR 2024 (as a First author of the paper "Local Search GFlowNets")
- **Qualcomm Innovation Fellowship Award** 2023 Korea (as a First author of the paper "Sym-NCO: Leveraging Symmetricity for Neural Combinatorial Optimization")
- NeurIPS 2022 **Scholar Award** (Travel Grant)
- DesignCon 2022 **Best Paper Award** (as a Second author for a paper of <a href="https://www.linkedin.com/in/haeyeon-rachel-kim/">Haeyeon Rachel Kim)
- DesignCon 2022 **Best Paper Award** (as a Second author for a paper of <a href="https://www.linkedin.com/in/seonguk-choi-6077731a9/"> Seonguk Choi)
- DesignCon 2021 **Best Paper Award** (as a First author)
- IEEE EDAPS 2020 **Best Student Paper Award** (as a Second author for a paper of <a href="https://www.linkedin.com/in/kyungjune-son-300a9318a/">Kyungjune Son)

### Academic activities

- Conference Reviewer: *NeurIPS*, *ICML*, *ICLR*, *AISTATS*, *AAAI*, *IJCAI*, Learning on Graphs (*LoG*)
- Journal Reviewer: IEEE Transactions on Neural Networks and Learning Systems (*TNNLS*)
